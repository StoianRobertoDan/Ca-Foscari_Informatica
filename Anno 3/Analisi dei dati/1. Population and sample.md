Glossary: 
- **Population**: all units of interest.
- **Parameter**: numerical characteristic of the population of interest. Notation: $\theta$.
- **Census** (censimento): observation of the population to value $\theta$.
- **Sample**: subset/subgroup of the population used to evaluate/estimate $\theta$ when the census is not appropriate.
- **Statistic**: any function of the data (either by census or sample).
- **Estimator**: statistic used to reconstruct $\theta$. Notation: $\widehat\theta$.
- **Estimate**: value of the estimator corresponding to the studied sample.

Errors: 
- The difference between the estimate and the parameter is due to two types of errors:
	- **Sampling** **errors**:
		- Inevitable.
		- Due to the limit of the sample.
		- Decreases more and more as the sample is bigger and if the estimator $\widehat\theta$ is reasonable.
	- **Non**-**sampling** **errors**:
		- Evitabile.
		- Due to the use of inappropriate sampling scheme, wrong statistical techniques or the use of an estimator $\widehat\theta$ that's not appropriated.
		- May or may not change with a bigger sample.

Random sampling:
- **Simple random sampling** is a sampling design where units are collected from the entire population independently of each other, all being equally likely to be sampled.
- It is a possible way to reduce non-sampling errors.
- Random sampling reduces distortions and having a specific subgroup of the population.
- Observations collected by means of a simple random sampling design are **IID** (independent and identically distributed).


Simple computing statistics:
- Mean: measuring the average value of sample. It is an estimate of the population mean: $E(X) = \mu$
	 - Notation: 
		 - $\mu$: population mean.
		 - $\overline X$: sample mean, estimator of $\mu$.
		 - $\overline x$: a particular estimate of $\mu$.
		 - $\sigma$: population standard deviation.
		 - $s$: sample standard deviation, estimator of $\sigma$.
		 - $\sigma^{2}$: population variance.
		 - $s^{2}$: sample variance, estimator of $\sigma$.
	- Is the arithmetic average: $\overline{X} = \frac{1}{n}\sum\limits^{n}_{i=1} X_{i} = \frac{X_{1}+...+X_{n}}{n}$.
	- Bias (distorsione):
		- Is defined as $Bias(\hat\theta) = \mathbf{E}(\hat\theta - \theta)$
		- Unbiasedness means that collecting a large number of samples and computing them on $\hat\theta$, on the average we hit the unknown parameter $\theta$ exactly.
			- Unbiased estimator neither underestimate nor overestimate the parameter on the long run.
		- An estimator $\hat\theta$ is unbiased for a parameter $\theta$ if its expectation equals the parameter: $\mathbf{E}(\hat\theta) = \theta$ for all possible values of $\theta$.
		- Sample mean estimates $\mu$ unbiasedly because its expectation is: $\mathbf{E}(\overline X) = \mathbf{E}(\frac{1}{n}\sum\limits_{i=1}^{n}X_{i}) = \frac{1}{n}\sum\limits_{i=1}^{n}\mathbf{E}(X_{i}) = \frac{1}{n}\sum\limits_{i=1}^{n}\mu = \frac{n\mu}{n} =\mu$
	- Consistency:
		- An estimator $\hat\theta$ is consistent for a parameter $\theta$ if the probability of its sampling error converges to 0 as the sample size increases to infinity.
			- $\mathbf{P}\{|\hat\theta - \theta|>\epsilon\} \rightarrow 0 \;\mbox{as}\; n\rightarrow\infty \; \forall\; \epsilon > 0$
		- The consistency of $\overline{X}$ follows directly from Chebyshev's inequality:
			- $Var(\overline{X}) = Var(\frac{1}{n}\sum\limits_{i=1}^{n}X_{i}) = \frac{1}{n^{2}}\sum\limits_{i=1}^{n}Var(X_{i}) = \frac{n\sigma^2}{n^{2}} =\frac{\sigma^{2}}{n}$
			- Chebyshev's inequality: $Pr\{|\overline{X} - \mu|>\epsilon\}\leq \frac{Var(\overline{X})}{\epsilon^{2}}$
			- $\Rightarrow Pr\{|\overline{X} - \mu|>\epsilon\}\leq \frac{\sigma^{2}\backslash n}{\epsilon^{2}} \rightarrow 0 \;as\; n\rightarrow\infty$
	- Asymptotic normality:
		- By the **Central Limit Theorem**, the sample mean have approximately Standard Normal distribution if they computed from a large sample.
		- Central Limit Theorem: $Z=\frac{\overline{X}-\mathbf{E}(\overline{X})}{Std\overline{X}}=\frac{\overline{X}-\mu}{\sigma\sqrt{n}}\rightarrow N(0,1)\; as\; n\rightarrow\infty$
- Median: measuring the central value.
	- notation: M.
	- Is the number that's exceeded by at most half of the observations and is preceded by at most a half of the observations.
		- $\left\{ \begin{array}{lcc} P\{X>M\} & \leq & 0.5 \\ P\{X<M\} & \geq & 0.5 \end{array}\right.$ 
	- Median il less prone to distortion from limit cases (less sensitive) than the mean.
		- Comparing mean and media:
			- $\left\{\begin{array}{lcc} \mbox{Symmetrical distribution} & \Rightarrow & M =\mu \\ \mbox{Right-skewed distribution} & \Rightarrow & M <\mu \\ \mbox{Left-skewed distribution} & \Rightarrow & M >\mu \end{array}\right.$
- Quantiles and quartiles