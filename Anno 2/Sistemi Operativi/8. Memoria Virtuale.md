
La memoria virtuale è una tecnica che consente ai sistemi operativi di gestire e assegnare la memoria in modo più efficiente rispetto alla quantità fisica di RAM disponibile su un sistema. In un sistema con memoria virtuale, il sistema operativo utilizza sia la RAM fisica disponibile che una porzione dello spazio su disco rigido come "memoria virtuale". Questo consente di eseguire processi più grandi di quanto la RAM fisica possa contenere completamente.

Le principali componenti della memoria virtuale includono:

1. **Indirizzi:**
- Due tipi di indirizzi nei sistemi di memoria virtuale:
	- Indirizzi virtuali:
		- Riferiti dai processi.
	- Indirizzi fisici:
		- Descrive indirizzi nella memoria principale.
- Memory management unit (MMU): 
	- Componente hw dedicata alla traduzione di indirizzi virtuali in indirizzi fisici
- ![[Pasted image 20240115143218.png]]

2. **Spazio di Indirizzamento Virtuale:**
- Ogni processo ha il suo spazio di indirizzamento virtuale, che rappresenta l'intero intervallo di indirizzi che il processo può utilizzare. Questo spazio di indirizzamento virtuale è diviso in parti come il codice eseguibile, i dati, lo stack e l'heap.
- Spazio di indirizzamento virtuale V:
	- Intervallo di indirizzi virtuali ai quali un processo può fare riferimento.
- Spazio di indirizzamento reale R:
	- Intervallo di indirizzi fisici disponibili su un particolare sistema di computer.
- Meccanismo di traduzione dinamica degli indirizzi (DAT – Dynamic Address Translation):
	- Converte indirizzi virtuali in indirizzi fisici durante l'esecuzione del programma.

2. **Mapping dei blocchi:
- Mappa di traduzione degli indirizzi:
	- Indica quali regioni dello spazio di indirizzamento virtuale di un processo sono attualmente in memoria principale e dove si trovano. 
- Informazioni organizzati in blocchi.
- Dimensione dei blocchi.
	- Frammentazione interna.
	- Tempo di trasferimento dei blocchi.
	- Variabile o fissa.
- Contiguità artificiale:
	- Indirizzi virtuali contigui potrebbero non corrispondere agli indirizzi di memoria reale contigui.
	- Il programmatore vede gli indirizzi virtuali contigui.
	- ![[Pasted image 20240115150556.png]]
- Tipi di blocchi:
	- Le pagine: 
		- Sono unità di memoria di dimensione fissa.
		- Sono gestite attraverso la **paginazione**.
		- Ha l'obiettivo di semplificare l'allocazione e il caricamento dinamico della memoria virtuale.
	- I segmenti:
		- Sono porzioni logiche o fisiche di memoria di dimensioni variabili.
		- Sono gestite attraverso la **segmentazione**.
		- Ha l'obbiettivo di fornire una maggiore flessibilità nella gestione di parti distinte di un processo.
	- ![[Pasted image 20240116144025.png]]
- Traduzione degli indirizzi dei blocchi:
	- ![[Pasted image 20240115152207.png]]

3. **Paginazione:**
   - La paginazione è una tecnica che divide la memoria fisica e virtuale in blocchi di dimensioni fisse chiamati "pagine". Il sistema operativo gestisce le pagine nella memoria virtuale e le assegna dinamicamente alla RAM fisica quando necessario.
-  ![[Pasted image 20240115143355.png]]
- ![[Pasted image 20240115152810.png]]
- Le pagine hanno un determinata misura $p_s$ che viene moltiplicato per il numero della pagina per avere l'indice nella page table. 
- Page table entry (PTE) (riga della tabella delle pagine):
	- Indica che la pagina virtuale p è nel page frame p'.
	- Contiene un bit di residenza, r, per indicare se la pagina è in memoria principale:
		- r = 1, PTE memorizza il numero di page frame p'.
		- r = 0, PTE memorizza la posizione della pagina in memoria secondaria.
- ![[Pasted image 20240115153511.png]]
- Paginazione con mapping diretto:
	- Traduzione dinamica degli indirizzi da virtuali a fisici con paginazione.
		- Simile alla traduzione di indirizzi di blocchi.
	- La tabella delle pagine contiene una riga per ogni pagina dello spazio virtuale V.
	- Richiede l’accesso alla memoria per ogni mapping di una pagina.
	- ![[Pasted image 20240115153934.png]]
- Paginazione con mapping associativo:
	- Mantenere tutta la tabella delle pagine in memoria cache spesso non è praticabile.
		- A causa di costo della memoria cache ad alta velocità, per spazi di indirizzamento di programmi relativamente grandi.
	- Aumentare le prestazioni di traduzione dinamica degli indirizzi:
		- Posizionare l’intera tabella delle pagine nella memoria associativa con indirizzamento per contenuto.
		- Ogni posizione nella memoria associativa è cercata contemporaneamente.
		- Costo elevato della memoria cache con indirizzamento per contenuto
	- ![[Pasted image 20240115154228.png]]
- Paginazione con mapping diretto/associativo:
	- Compromesso fra costo e prestazioni.
	- PTE sono prevalentemente memorizzati nelle tabelle direttamente mappate nella memoria principale.
	- PTE utilizzate più di recente sono memorizzati nella memoria cache associativa ad alta velocità chiamata Traduzione Lookaside Buffer (TLB).
		- Se PTE non si trova nel TLB, il meccanismo DAT ricerca nella tabella nella memoria principale.
	- Può portare ad alte prestazioni con un TLB relativamente piccolo, grazie al principio di località temporale.
		- È probabile che una pagina riferita recentemente da un processo sia nuovamente riferita in tempi brevi.
	- TLB è controllabile sia hardware (parte delle MMU) sia dal s.o.
	- ![[Pasted image 20240115154450.png]]

4. **Tabelle di pagine multilivello:**
- Sistema in grado di memorizzare locazioni non contigue di memoria quali parti della tabella delle pagine di processo che il processo sta utilizzando.
- Riduce il numero di righe della tabella in memoria.
- Gerarchia delle tabelle di pagina:
	- Ogni livello contiene una tabella che memorizza i puntatori alle tabelle del livello inferiore.
	- I livelli più bassi hanno tabelle con le traduzioni di indirizzi.
- Può ridurre l’overhead di memoria rispetto al sistema di mappatura diretta.
- Richiede un accesso alla memoria in più per il mapping, limitabile con località e uso di TLB.
- ![[Pasted image 20240116104318.png]]

5. **Tabella inversa delle pagine:**
- La tabella multilivello riduce il numero di righe della tabella in memoria, utile se il processo usa solo una parte dello spazio di indirizzamento.
- La tabella inversa memorizza un PTE (riga della tabella delle pagine) in memoria per ogni page frame del sistema:
	- Il numero di righe della tabella in memoria dipende non dallo spazio ma dal numero di page frame (memoria fisica).
- È l’inverso rispetto ad una tabella di pagine tradizionale:
	- *paragrafo successivo
- Non memorizza informazioni relative alla memoria secondaria.
- Utilizza funzioni hash per mappare l’indirizzo virtuale nella riga nella tabella inversa delle pagine
- Hashing può causare collisioni che aumentano il tempo di traduzione dell’indirizzo aumentando il numero di accessi alla memoria:
	- Collisione: 
		- Quando più indirizzi virtuali tradotti con hash danno lo stesso valore (numero di page frame).
		- Concatenamento (chaining) per evitare sovrascritture di elementi in collisione.
		- Possibile diminuzione delle collisioni aumentando l’intervallo dei valori della funzione hash.
	- Non si può aumentare la dimensione della tabella inversa delle pagine perché deve memorizzare esattamente una PTE per ogni page frame.
	- Hash Anchor Table (HAT) aumenta l’intervallo dei valori della funzione hash con l'aggiunta di un ulteriore livello indiretto:
		- La dimensione deve essere scelta attentamente per bilanciare la frammentazione della tabella, l’overhead e le prestazioni.
- ![[Pasted image 20240116112522.png]]

6. **Funzionamento della paginazione normale e inversa**
- Paginazione Normale (Forward Paging):
	- Divisione della Memoria Virtuale:
	    - La memoria virtuale è divisa in pagine di dimensioni fisse.
	- Divisione della Memoria Fisica:
	    - La memoria fisica (RAM) è suddivisa in frame, che sono blocchi di dimensioni identiche a quelle delle pagine.
	- Mappatura tra Pagina e Frame:
	    - Una tabella delle pagine mantiene la corrispondenza tra il numero di pagina virtuale e il numero del frame fisico. Ogni entry nella tabella delle pagine contiene l'indirizzo del frame fisico corrispondente alla pagina virtuale.
	- Accesso alla Memoria Virtuale:
	    - Quando un processo accede a un indirizzo virtuale, il sistema operativo utilizza la tabella delle pagine per trovare l'indirizzo fisico corrispondente. L'indirizzo fisico ottenuto viene poi utilizzato per l'accesso effettivo alla memoria fisica.
	- Vantaggi della Paginazione Normale:
	    - Semplice da implementare e gestire.
    - Consentono una gestione efficiente della memoria virtuale.
- **Paginazione Inversa (Reverse Paging):**
	- Divisione della Memoria Virtuale e Fisica:
	    - La memoria virtuale è suddivisa in pagine, ma la memoria fisica (RAM) non è suddivisa in frame.
	- Mappatura tra Pagina e Frame:
	    - Una tabella delle pagine inversa (o "tabella dei frame") mantiene la corrispondenza tra il numero del frame fisico e il numero di pagina virtuale. Ogni entry nella tabella dei frame contiene l'indirizzo della pagina virtuale corrispondente.
	- Accesso alla Memoria Virtuale:
	    - Quando un processo accede a un indirizzo virtuale, il sistema operativo utilizza la tabella dei frame per trovare il numero di pagina virtuale corrispondente. L'indirizzo virtuale è implicitamente dato dal numero del frame fisico.
	- Vantaggi della Paginazione Inversa:
	    - Riduzione della dimensione della tabella delle pagine. Poiché ogni frame corrisponde a una pagina, la tabella delle pagine è più piccola.
	- Svantaggi della Paginazione Inversa:
	    - Implementazione più complessa rispetto alla paginazione normale.
	    - La frammentazione interna può essere un problema, poiché l'allocazione e il rilascio di pagine possono causare frammentazione.

7. **Sostituzione in un sistema a paginazione:**
- Quando viene richiesto l'accesso ad una parte di memoria che si trova in memoria virtuale e non in memoria fisica viene fatta una sostituzione, caricando la parte di memoria virtuale in memoria fisica e sovrascrivendo quello che era precedentemente scritto.
- Strategie di sostituzione:
	- Tecnica usata da un sistema per selezionare le pagine da sostituire quando la memoria è piena.
	- Determina dove caricare in memoria principale una pagina o un segmento da inserire.
- Strategie di Fetch:
	- Determina quando le pagine o segmenti devono essere caricati nella memoria principale.
	- Strategie a richiesta nel momento in cui il processo vi fa riferimento.
	- Strategie a previsione:
		- Uso di euristiche per prevedere a quali pagine un processo farà presto riferimento e caricamento di quelle pagine o segmenti. 
	- Maggior overhead.
- Processo tende a fare riferimento alla memoria secondo modelli altamente localizzati:
	- Località spaziale.
	- Località temporale.
- Quando un processo genera un page fault, il gestore della memoria deve:
	- **Individuare** la pagina di memoria secondaria a cui fa riferimento.
	- **Caricarla** nel page frame della memoria principale.
	- **Aggiornare** la riga corrispondente della tabella delle pagina.
	- Se la pagina precedente era stata modificata bisogna caricarla sul disco:
		- Bit di modifica (dirty bit):
			- 1 se la pagina è stata modificata, 0 altrimenti.
			- Aiuta il sistema a determinare rapidamente la modifica di pagina.
		- Scrittura su disco (flush) di una pagina modificata: overhead.
			- Sistemi con flush periodico automatico (preventivo).
- Tecniche di sostituzione:
	- Sostituzione randomica:
		- Strategia di sostituzione di pagina con basso overhead, semplice e veloce.
		- Equa: ogni pagina nella memoria principale ha una uguale probabilità di essere selezionata per la sostituzione.
		- Potrebbe facilmente selezionare come prossima pagina da sostituire anche la pagina che alla quale verrà fatto il prossimo riferimento.
	- First-In-First-Out (FIFO):
		- Sostituisce la pagina che è stata nel sistema il più a lungo (ordine in base al tempo di arrivo).
		- Può sostituire anche le pagine molto utilizzate.
		- Può essere implementata con overhead relativamente basso.
		- Non conveniente (non praticabile) per la maggior parte dei sistemi ma base per altre strategie.
	- Least-Recently-Used (LRU):
		- Sfrutta la località temporale sostituendo la pagina che ha trascorso più tempo in memoria senza essere riferita.
		- Può portare a prestazioni migliori rispetto FIFO:
			- Maggior overhead di sistema:
				- Aggiornamento dei link ad ogni accesso alla memoria.
				- Lista delle pagine.
				- Oppure uso di un contatore per ogni riga di pagina nella tabella.
		- LRU può portare a scarse prestazioni se la pagina meno utilizzata di recente è la prossima pagina a cui fa riferimento un programma in una iterazione all'interno di un ciclo che fa riferimento a diverse pagine:
			- Ad ogni sostituzione la pagina se riferita va ricaricata.
	- Least-Frequently-Used (LFU):
		- Sostituisce la pagina che è meno intensamente riferita.
		- Basato sul euristica che una pagina alla quale non si fa riferimento spesso non è probabile che sia riferita in futuro.
		- Potrebbe facilmente selezionare la pagina sbagliata per la sostituzione:
			- Una pagina che è stata molto riferita in passato può non essere più riferita di nuovo, ma rimarrà in memoria mentre altre pagine attive più recenti vengono sostituite.
	- Not-Frequently-Used (NFU):
		- Sostituisce la pagina che è non è stata recentemente riferita:
			- Usa un contatore associato ad ogni pagina e inizializzato a 0.
			- Ad ogni interrupt del clock il s.o. fa la scansione dei bit delle pagine di memoria e somma il bit R al contatore, che tiene così traccia del numero di riferimenti.
			- Si sceglie la pagina con il valore del contatore minimo
	- Not-Recently-Used (NRU):
		- Approssima la strategia LRU con un overhead minimo utilizzando il bit di riferimento e il bit di modifica per determinare quale pagina non è stata utilizzata di recente e può essere rapidamente sostituita:
			- Bit di riferimento = 0 se la pagina non è stata riferita, 1 altrimenti (bit di accesso).
			- Bit di modifica = 0 se la pagina non è stata modificata 1 altrimenti.
			- Due bit hw nella tabella delle pagine. 
			- Cerca una pagina non riferita (approssima LRU).
			- Se non la trova cerca un pagina non modificata
		- Può essere implementata su macchine che non dispongono di bit di riferimento e / o bit di modifica hardware (simulabile sw).
		- Con molti utenti le pagine vengono spesso tutte riferite.
		- Periodicamente si possono azzerare i bit di riferimento.
	- Second-Chance e Sostituzione a orologio:
		- Strategie di tipo FIFO ma esamina il bit di riferimento della pagina più vecchia:
			- Se è off (0) la strategia seleziona la pagina per la sostituzione.
			- Se è on (1) la strategia azzera il bit e sposta la pagina in coda FIFO e si considera come un nuovo arrivo.
		- Assicura che le pagine attive siano quelle con minor probabilità di essere sostituite.
	- Far (lontananza delle pagine):
		- Crea un grafo di accesso che rappresenta il modello dei riferimenti di un processo:
			- Grafo: 
				- Nodi=pagine.
				- Archi=riferimenti.
		- Sostituisce la pagina non referenziato che è più lontana nel grafo di accesso da qualsiasi pagina riferita.
		- Prestazioni a livelli quasi ottimali.
		- Non è stata solitamente implementata in sistemi reali:
			- La ricerca e gestione del grafo di accesso è complessa e senza supporto hardware

8. **Dimensioni delle pagine:**
- Dimensione piccola di pagina:
	- Minor frammentazione interna.
	- Può ridurre la quantità di memoria necessaria per contenere working set di un processo.
	- Maggior memoria disponibile per altri processi.
		- Minor spreco di memoria.
	- Tabella delle pagine più grande.
- Dimensione grande di pagina:
	- Riduce la memoria sprecata dalla frammentazione della tabella.
	- Abilita ogni riga della TLB a mappare una regione della memoria più grande, migliorando le prestazioni.
	- Riduce il numero di operazioni di I/O del sistema per caricare il working set di un processo in memoria.
- Dimensione multipla di pagina:
	- Possibile frammentazione esterna.

9. **Segmentazione:**
- Segmento:
	- Contiene porzioni significative del programma (es. procedure, array, stack).
	- Composto da posizioni contigue.
	- I segmenti non devono necessariamente essere della stessa dimensione né devono essere adiacenti in memoria principale.
	- Il segmento è un concetto logico e non fisico (come per la pagina)
- Un processo può essere in esecuzione mentre le sue istruzioni correnti e i dati riferiti sono in segmenti di memoria principale.
- Se il processo fa riferimento a dati in memoria secondaria il segmento corrispondente va caricato.
- Riga della tabella della mappa dei segmenti:
	- Indica che quel segmento s inizia all’indirizzo di memoria reale s’.
	- Contiene un bit di residenza, r, che indica se il segmento è in memoria:
		- Se r = 1, s’ memorizza l'indirizzo di base del segmento.
		- Se r = 0 , a memorizza la posizione del segmento in memoria secondaria.
	- Inoltre contiene un campo lunghezza, l, che indica la dimensione del segmento.
	- Può essere usato per evitare che un processo riferisca indirizzi fuori dal segmento (eccezione di overflow del segmento).
	- Bit di protezione per controllare se il tipo di operazione è ammessa (eccezione di protezione del segmento).
	- ![[Pasted image 20240116142400.png]]
- Mapping Diretto:
	- ![[Pasted image 20240116142627.png]]
- Uno schema per implementare la protezione della memoria nei sistemi di segmentazione è chiavi di protezione della memoria.
	- Chiave di protezione.
	- Valore associato ad un processo:
		- Se la chiave di protezione per il processore e il blocco richiesto sono gli stessi, il processo può accedere al segmento.
	- Chiavi manipolabili solo da istruzioni privilegiate.
	- Uno schema più comune è quello di utilizzare i bit di protezione che specificano se un processo è autorizzato a compiere operazioni (diritti di accesso ai segmenti).
	- ![[Pasted image 20240116143246.png]]
- Controllo degli accessi alla tabella dei segmenti:
	- Se il segmento non è in memoria, viene generato un fallimento di accesso al segmento (missing-segment fault).
	- Se d > l, viene generata un'eccezione di overflow del segmento (overflow-segment exception).
	- Se non è consentita l'operazione (es. read, write, execute, append), viene generata un'eccezione di protezione di segmento (segmentprotection exception).

10. **Sistemi con paginazione e segmentazione:**
- Per sfruttare i vantaggi delle due tecniche.
- I segmenti occupano una o più pagine.
	- Tutte le pagine del segmento non devono necessariamente essere in memoria principale contemporaneamente.
- Le pagine contigue nella memoria virtuale non devono essere contigui nella memoria principale.
- Indirizzo di memoria virtuale è implementato come una tripla ordinata:
	- ![[Pasted image 20240116144712.png]]
- ![[Pasted image 20240116144853.png]]
- ![[Pasted image 20240116144947.png]]

- **Esecuzione di Processi di Dimensioni Maggiori:** I processi possono essere più grandi della quantità di RAM fisica disponibile, poiché solo una parte del processo deve risiedere in RAM in un dato momento.

- **Isolamento e Protezione:** Ogni processo ha il suo spazio di indirizzamento virtuale, fornendo isolamento e protezione tra i processi.

- **Condivisione di Codice e Dati:** Processi diversi possono condividere lo stesso codice o dati, risparmiando memoria.

La gestione della memoria virtuale è una parte cruciale dei moderni sistemi operativi, consentendo loro di gestire efficacemente la memoria disponibile e migliorare le prestazioni complessive del sistema.